{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55188710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "使用MPI4Py并行处理光谱文件分析\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# 假设这是你的光谱分析类\n",
    "class SpectrumLineFitter:\n",
    "    def __init__(self):\n",
    "        # 初始化参数\n",
    "        pass\n",
    "\n",
    "    def analyze_spectrum(self, spectrum_file):\n",
    "        \"\"\"\n",
    "        分析单个光谱文件的函数\n",
    "        返回分析结果\n",
    "        \"\"\"\n",
    "        # 这里是你的光谱分析代码\n",
    "        # 示例代码，请替换为你的实际实现\n",
    "        try:\n",
    "            # 读取和分析光谱文件\n",
    "            result = {\n",
    "                'filename': spectrum_file,\n",
    "                'status': 'success',\n",
    "                'analysis_data': 'your_analysis_results_here'\n",
    "            }\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'filename': spectrum_file,\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "def get_spectrum_files(directory_path, pattern=\"*.fits\"):\n",
    "    \"\"\"\n",
    "    获取所有光谱文件列表\n",
    "    \"\"\"\n",
    "    spectrum_files = glob.glob(os.path.join(directory_path, pattern))\n",
    "    return spectrum_files\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"\n",
    "    将列表分成n个大致相等的块\n",
    "    \"\"\"\n",
    "    k, m = divmod(len(lst), n)\n",
    "    return [lst[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n)]\n",
    "\n",
    "def main():\n",
    "    # 初始化MPI\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    # 配置参数\n",
    "    spectrum_directory = \"/path/to/your/spectrum/files\"  # 修改为你的光谱文件目录\n",
    "    output_directory = \"/path/to/output\"  # 修改为输出目录\n",
    "    file_pattern = \"*.fits\"  # 修改为你的文件模式，如 \"*.dat\", \"*.txt\" 等\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"开始使用 {size} 个进程进行并行光谱分析...\")\n",
    "\n",
    "        # 主进程获取所有光谱文件\n",
    "        spectrum_files = get_spectrum_files(spectrum_directory, file_pattern)\n",
    "        total_files = len(spectrum_files)\n",
    "\n",
    "        if total_files == 0:\n",
    "            print(f\"在目录 {spectrum_directory} 中没有找到匹配模式 {file_pattern} 的文件\")\n",
    "            comm.Abort()\n",
    "\n",
    "        print(f\"找到 {total_files} 个光谱文件\")\n",
    "\n",
    "        # 将文件列表分配给各个进程\n",
    "        file_chunks = chunk_list(spectrum_files, size)\n",
    "\n",
    "        # 确保输出目录存在\n",
    "        Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    else:\n",
    "        file_chunks = None\n",
    "\n",
    "    # 广播文件分块到所有进程\n",
    "    my_files = comm.scatter(file_chunks, root=0)\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"文件分配完成，每个进程分配到 {[len(chunk) for chunk in file_chunks]} 个文件\")\n",
    "\n",
    "    # 每个进程处理分配给它的文件\n",
    "    fitter = SpectrumLineFitter()\n",
    "    local_results = []\n",
    "\n",
    "    print(f\"进程 {rank}: 开始处理 {len(my_files)} 个文件...\")\n",
    "\n",
    "    for i, spectrum_file in enumerate(my_files):\n",
    "        if rank == 0 and i % 100 == 0:\n",
    "            print(f\"进程 {rank}: 已处理 {i}/{len(my_files)} 个文件\")\n",
    "\n",
    "        # 分析光谱\n",
    "        result = fitter.analyze_spectrum(spectrum_file)\n",
    "        local_results.append(result)\n",
    "\n",
    "    print(f\"进程 {rank}: 完成处理 {len(my_files)} 个文件\")\n",
    "\n",
    "    # 收集所有进程的结果到主进程\n",
    "    all_results = comm.gather(local_results, root=0)\n",
    "\n",
    "    if rank == 0:\n",
    "        # 主进程合并所有结果\n",
    "        final_results = []\n",
    "        for process_results in all_results:\n",
    "            final_results.extend(process_results)\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "\n",
    "        print(f\"\\n并行处理完成!\")\n",
    "        print(f\"总处理时间: {total_time:.2f} 秒\")\n",
    "        print(f\"处理文件数量: {len(final_results)}\")\n",
    "        print(f\"平均每个文件处理时间: {total_time/len(final_results):.4f} 秒\")\n",
    "\n",
    "        # 统计成功和失败的数量\n",
    "        success_count = sum(1 for r in final_results if r['status'] == 'success')\n",
    "        error_count = len(final_results) - success_count\n",
    "\n",
    "        print(f\"成功处理: {success_count} 个文件\")\n",
    "        print(f\"处理失败: {error_count} 个文件\")\n",
    "\n",
    "        # 保存结果\n",
    "        output_file = os.path.join(output_directory, \"spectrum_analysis_results.pkl\")\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(final_results, f)\n",
    "        print(f\"结果已保存到: {output_file}\")\n",
    "\n",
    "        # 如果有错误，保存错误日志\n",
    "        if error_count > 0:\n",
    "            error_file = os.path.join(output_directory, \"error_log.txt\")\n",
    "            with open(error_file, 'w') as f:\n",
    "                for result in final_results:\n",
    "                    if result['status'] == 'error':\n",
    "                        f.write(f\"{result['filename']}: {result['error']}\\n\")\n",
    "            print(f\"错误日志已保存到: {error_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dustcurve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
